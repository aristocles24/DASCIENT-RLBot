{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10+"},"title":"Aristocles-Trend Decision Aid (Aristocles-Trend-Engine)"},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/ko-trend-decision-aid?scriptVersionId=297294444\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"937db409","cell_type":"markdown","source":"# KO-Trend-Engine\n\n**Notebook purpose:** A comprehensive, educational implementation companion to `spec.md` for the **KO-Trend Daily Decision Aid**.\n\nThis notebook is designed to be:\n- **Resourceful**: includes background, formulas, and implementation notes\n- **Practical**: runnable reference implementation with sane defaults\n- **Extensible**: clear seams for caching, persistence, and future signals\n\n**Date generated:** 2026-02-12\n\n> Important: This notebook pulls market data and sentiment from external services. Expect rate limits. Use batching, delays, and retries exactly as shown.","metadata":{}},{"id":"d4105056","cell_type":"markdown","source":"## Table of contents\n\n1. Problem framing and decision aid scope  \n2. Data pipeline and hybrid-source architecture  \n3. Golden parameters (strategy constants)  \n4. Indicator math and vectorized implementations  \n   - Bollinger Bands (20, 2)  \n   - RSI (14)  \n   - Rolling VWAP approximation  \n   - Klinger Oscillator (KO)  \n   - Awesome Oscillator (AO) (optional visual confirmation)  \n5. Decision logic (Entry, Exit, Ranking)  \n6. End-to-end runner (CLI-style output inside notebook)  \n7. Validation, troubleshooting, and extension ideas  \n","metadata":{}},{"id":"de1146a5","cell_type":"markdown","source":"## 1) Problem framing\n\n**Goal:** Each trading day, algorithmically identify, filter, and rank high-probability candidates from:\n- **Top 100 Trending**\n- **Top 100 Day Gainers**\n\nTwo primary setup classes:\n- **Trend Following**: momentum continuation with confirmation\n- **Drastic Deviation**: volatility breakout plus volume and momentum confirmation\n\nCore signals combine:\n- **Klinger Volume Force** (momentum with volume force)\n- **Bollinger volatility breakouts** (2-sigma deviation above upper band)\n- **RSI climax theory** (entry threshold and extreme overheated exit)\n- **VWAP anchor** (price acceptance above average value)\n\nThis is a **decision support system**, not an auto-trader.\n","metadata":{}},{"id":"72e041dc","cell_type":"markdown","source":"## 2) System architecture (Filter then Fetch)\n\nThe architecture minimizes both rate limits and compute by doing cheap screening first and expensive OHLCV retrieval later.\n\n### Stages\n\n| Stage | Source | Endpoint / Method | Purpose | Typical volume |\n|---|---|---|---|---:|\n| Discovery | `aristocles24` | `/api/yahoo/trending`, `/api/yahoo/screener` | Get raw candidates | ~200 |\n| Sentiment | `aristocles24` | `/api/sentiment` | Gatekeeper filter | ~200 (async) |\n| Technical | Yahoo Finance | `yfinance` | 3 months daily OHLCV | ~100 to 150 |\n\n### Key engineering techniques\n- **asyncio + aiohttp** for sentiment filtering\n- **vectorized numpy/pandas** for indicators (avoid loops over rows)\n- **smart batching** for yfinance downloads: batch size 10 with a delay\n- **session masquerading** for Yahoo blocks: custom User-Agent\n- **retry logic** with exponential backoff (network resiliency)\n\nBelow, you will implement each component and then run the full pipeline.\n","metadata":{}},{"id":"3eb82789","cell_type":"markdown","source":"## 3) Environment setup\n\nThis notebook targets **Python 3.10+**.\n\nIf you run this in a fresh environment, install dependencies first.\n","metadata":{}},{"id":"9344ffe8","cell_type":"code","source":"# If needed, uncomment and run:\n# %pip install -U aiohttp yfinance pandas numpy tabulate colorama requests urllib3","metadata":{},"outputs":[],"execution_count":null},{"id":"313b6901","cell_type":"markdown","source":"## 4) Configuration (Golden Parameters)\n\nThese constants are your backtest-derived or spec-defined guardrails.\n\nNotes:\n- **PARAM_VOL_MULT**: institutional volume requirement\n- **PARAM_RSI_ENTRY**: prevents weak breakouts\n- **PARAM_RSI_EXIT**: RSI climax top\n- **PARAM_SENTIMENT**: minimum AI sentiment score\n- **BATCH_SIZE / DELAY_SECONDS**: rate limiting strategy for Yahoo\n","metadata":{}},{"id":"2016200e","cell_type":"code","source":"from __future__ import annotations\n\nimport asyncio\nimport time\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport aiohttp\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\n\nfrom tabulate import tabulate\nfrom colorama import Fore, Style, init as colorama_init\nfrom requests import Session\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\ncolorama_init(autoreset=True)\n\n# --- 1. CONFIGURATION (THE GOLDEN PARAMETERS) ---\nBASE_URL = \"https://stocks.aristocles24.workers.dev/api\"\n\nBATCH_SIZE = 10\nDELAY_SECONDS = 2.0\n\nPARAM_VOL_MULT = 1.5\nPARAM_RSI_ENTRY = 55\nPARAM_RSI_EXIT = 95\nPARAM_SENTIMENT = 45\n\n# Practical safeguards\nMIN_HISTORY_DAYS = 60   # KO uses EMAs; ensure enough history\nYF_PERIOD = \"3mo\"\nYF_INTERVAL = \"1d\"\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c15c3ab6","cell_type":"markdown","source":"## 5) Network utilities\n\n### 5.1 Yahoo Finance session masquerading + retries\n\nYahoo sometimes blocks default clients. A browser-like session and retry policy help mitigate transient network issues.\n\n- `Retry(connect=3, backoff_factor=0.5)` retries connection failures with exponential backoff.\n- A modern User-Agent reduces block probability.\n","metadata":{}},{"id":"e8c2a231","cell_type":"code","source":"def get_yf_session() -> Session:\n    \"\"\"Creates a browser-like session to reduce Yahoo blocking.\n    \n    Returns\n    -------\n    requests.Session\n        Configured session with retry adapter and User-Agent header.\n    \"\"\"\n    session = Session()\n    retry = Retry(connect=3, backoff_factor=0.5)\n    adapter = HTTPAdapter(max_retries=retry)\n    session.mount(\"http://\", adapter)\n    session.mount(\"https://\", adapter)\n    session.headers.update({\n        \"User-Agent\": (\n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n            \"Chrome/114.0.0.0 Safari/537.36\"\n        )\n    })\n    return session\n\n\nasync def fetch_json(session: aiohttp.ClientSession, url: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Fetch JSON payloads safely.\n    \n    - Returns None on non-200 or exceptions\n    - Keeps pipeline robust to flaky endpoints\n    \"\"\"\n    try:\n        async with session.get(url) as response:\n            if response.status == 200:\n                return await response.json()\n            return None\n    except Exception:\n        return None\n","metadata":{},"outputs":[],"execution_count":null},{"id":"2622deb0","cell_type":"markdown","source":"## 6) Data ingestion (Discovery + Sentiment)\n\n### 6.1 Discovery: Trending + Day Gainers\n\nWe combine both lists, then clean symbols.\nA conservative cleaning rule is used: `symbol.isalpha()` to avoid invalid entries.\n","metadata":{}},{"id":"e4e8cf62","cell_type":"code","source":"async def get_candidates() -> List[str]:\n    \"\"\"Fetch Trending and Day Gainers candidates from aristocles24 endpoints.\"\"\"\n    print(f\"{Fore.CYAN}[*] fetching candidate list (trending + gainers)...\")\n    async with aiohttp.ClientSession() as session:\n        task1 = fetch_json(session, f\"{BASE_URL}/yahoo/trending\")\n        task2 = fetch_json(session, f\"{BASE_URL}/yahoo/screener?scrIds=day_gainers&count=100\")\n\n        res_trend, res_gain = await asyncio.gather(task1, task2)\n\n    candidates = set()\n\n    if res_trend and \"symbols\" in res_trend:\n        candidates.update(res_trend[\"symbols\"])\n    if res_gain and \"symbols\" in res_gain:\n        candidates.update(res_gain[\"symbols\"])\n\n    clean_candidates = [s for s in candidates if isinstance(s, str) and s.isalpha()]\n    print(f\"{Fore.GREEN}[+] found {len(clean_candidates)} unique candidates.\")\n    return clean_candidates","metadata":{},"outputs":[],"execution_count":null},{"id":"d77b463c","cell_type":"markdown","source":"### 6.2 Sentiment gatekeeper (async)\n\nWe filter out:\n- `score < PARAM_SENTIMENT` (default 45)\n- `bucket == 'BEARISH'`\n\nConcurrency is limited via `asyncio.Semaphore(10)` to avoid flooding the API.\n\nThis is a major efficiency win: technical downloads happen only for survivors.\n","metadata":{}},{"id":"7b78d0e4","cell_type":"code","source":"@dataclass(frozen=True)\nclass SentimentResult:\n    symbol: str\n    score: float\n    bucket: str\n\n\nasync def filter_by_sentiment(candidates: List[str]) -> List[SentimentResult]:\n    \"\"\"Filter candidates using aristocles24 sentiment API.\"\"\"\n    print(f\"{Fore.CYAN}[*] filtering by sentiment (score >= {PARAM_SENTIMENT}, not BEARISH)...\")\n\n    semaphore = asyncio.Semaphore(10)\n\n    async def check_sentiment(session: aiohttp.ClientSession, symbol: str) -> Optional[SentimentResult]:\n        async with semaphore:\n            data = await fetch_json(session, f\"{BASE_URL}/sentiment?symbol={symbol}\")\n            if not data or not data.get(\"ok\"):\n                return None\n            try:\n                blend = data.get(\"blend\", {}) or {}\n                score = float(blend.get(\"overallScore\", 50))\n                bucket = str(blend.get(\"bucket\", \"NEUTRAL\"))\n\n                if score >= PARAM_SENTIMENT and bucket != \"BEARISH\":\n                    return SentimentResult(symbol=symbol, score=score, bucket=bucket)\n            except Exception:\n                return None\n            return None\n\n    async with aiohttp.ClientSession() as session:\n        tasks = [check_sentiment(session, sym) for sym in candidates]\n        results = await asyncio.gather(*tasks)\n\n    valid = [r for r in results if r is not None]\n    print(f\"{Fore.GREEN}[+] {len(valid)} candidates passed sentiment filter.\")\n    return valid","metadata":{},"outputs":[],"execution_count":null},{"id":"e8dc34f9","cell_type":"markdown","source":"## 7) Indicator engine (vectorized)\n\nThis section implements the dataset described in the spec.\n\n### 7.1 Bollinger Bands (20, 2)\n- Middle: 20-day SMA\n- Upper: SMA + 2 * STD\n- Lower: SMA - 2 * STD\n\n### 7.2 RSI (14)\nStandard Wilder RSI is typically computed with Wilder's smoothing.\nFor speed and readability, we use a rolling mean approximation consistent with your provided script.\nYou can swap it for an EMA-based Wilder smoothing if desired.\n\n### 7.3 VWAP (rolling approximation)\nFor daily OHLCV, an intraday VWAP is not available. We use a common approximation:\n- Typical price: (High + Low + Close) / 3\n- Cumulative VWAP: cumsum(TP * Volume) / cumsum(Volume)\n\n### 7.4 Klinger Oscillator (KO)\nThis follows your spec-aligned implementation:\n- Trend sign from TP differences\n- VF uses volume, trend, and a normalized range term\n- KO is EMA(34) - EMA(55) of VF\n- Signal is EMA(13) of KO\n- Histogram is KO - Signal\n\n### 7.5 Awesome Oscillator (AO) (optional)\nAO = SMA(5, median price) - SMA(34, median price)\nMedian price = (High + Low) / 2\n","metadata":{}},{"id":"dd8de8a1","cell_type":"code","source":"def compute_indicators(df: pd.DataFrame) -> Optional[pd.Series]:\n    \"\"\"Compute all indicators for a single ticker OHLCV dataframe.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Expected columns: Open, High, Low, Close, Volume\n    \n    Returns\n    -------\n    pd.Series | None\n        Latest row with derived indicator columns, or None if insufficient history.\n    \"\"\"\n    if df is None or df.empty or len(df) < MIN_HISTORY_DAYS:\n        return None\n\n    df = df.copy()\n\n    # A) Bollinger Bands (20, 2)\n    df[\"sma_20\"] = df[\"Close\"].rolling(window=20).mean()\n    df[\"std_20\"] = df[\"Close\"].rolling(window=20).std(ddof=0)\n    df[\"bb_upper\"] = df[\"sma_20\"] + (2 * df[\"std_20\"])\n    df[\"bb_lower\"] = df[\"sma_20\"] - (2 * df[\"std_20\"])\n\n    # B) RSI (14) rolling approximation\n    delta = df[\"Close\"].diff()\n    gain = delta.where(delta > 0, 0.0).rolling(window=14).mean()\n    loss = (-delta.where(delta < 0, 0.0)).rolling(window=14).mean()\n    rs = gain / (loss.replace(0, np.nan))\n    df[\"rsi\"] = 100 - (100 / (1 + rs))\n\n    # C) VWAP approximation (cumulative over period)\n    df[\"tp\"] = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3.0\n    df[\"vwap\"] = (df[\"tp\"] * df[\"Volume\"]).cumsum() / (df[\"Volume\"].cumsum().replace(0, np.nan))\n\n    # D) Klinger Oscillator (KO)\n    df[\"tp_diff\"] = df[\"tp\"].diff()\n    df[\"trend\"] = np.where(df[\"tp_diff\"] > 0, 1, -1)\n\n    df[\"dm\"] = df[\"High\"] - df[\"Low\"]\n    df[\"cm\"] = df[\"dm\"] + df[\"High\"].diff().abs() + df[\"Low\"].diff().abs()\n    df[\"cm\"] = df[\"cm\"].replace(0, 0.0001)\n\n    df[\"term\"] = (2 * (df[\"dm\"] / df[\"cm\"]) - 1).abs()\n    df[\"vf\"] = df[\"Volume\"] * df[\"trend\"] * df[\"term\"] * 100\n\n    df[\"ko\"] = df[\"vf\"].ewm(span=34, adjust=False).mean() - df[\"vf\"].ewm(span=55, adjust=False).mean()\n    df[\"ko_sig\"] = df[\"ko\"].ewm(span=13, adjust=False).mean()\n    df[\"ko_hist\"] = df[\"ko\"] - df[\"ko_sig\"]\n\n    # Volume SMA (20)\n    df[\"vol_sma\"] = df[\"Volume\"].rolling(window=20).mean()\n\n    # E) Awesome Oscillator (optional)\n    mp = (df[\"High\"] + df[\"Low\"]) / 2.0\n    df[\"ao\"] = mp.rolling(5).mean() - mp.rolling(34).mean()\n\n    latest = df.iloc[-1]\n\n    # Ensure key fields are present and finite\n    required = [\"Close\", \"Volume\", \"sma_20\", \"bb_upper\", \"rsi\", \"ko\", \"ko_sig\", \"ko_hist\", \"vwap\", \"vol_sma\"]\n    if any(pd.isna(latest.get(k, np.nan)) for k in required):\n        return None\n\n    return latest","metadata":{},"outputs":[],"execution_count":null},{"id":"e717b84f","cell_type":"markdown","source":"## 8) Decision logic\n\n### 8.1 Entry (STRONG BUY)\nA candidate triggers **BUY** if all conditions are met:\n1. Close > BB_Upper\n2. Volume > PARAM_VOL_MULT * Vol_SMA_20\n3. RSI > PARAM_RSI_ENTRY\n4. KO_Hist > 0\n5. Close > VWAP\n\n### 8.2 Exit\nA candidate triggers **SELL** if any condition is met:\n1. RSI > PARAM_RSI_EXIT (climax top)\n2. Close < BB_Middle (sma_20)\n\n### 8.3 Trend Following BUY\nIf not in breakout, a lighter BUY condition:\n- KO > KO_Signal and RSI > 50\n\n### 8.4 Ranking\nSort priority:\n1. STRONG BUY > BUY > HOLD > SELL > WAIT\n2. Magnitude of KO_Hist\n3. Sentiment score\n\nWe implement a stable sort key that produces this ordering.\n","metadata":{}},{"id":"640df8b4","cell_type":"code","source":"def classify_decision(row: pd.Series) -> str:\n    \"\"\"Apply exit-first and entry logic to a latest-indicator row.\"\"\"\n    # 1) Climax sell\n    if row[\"rsi\"] > PARAM_RSI_EXIT:\n        return \"SELL (CLIMAX)\"\n\n    # 2) Trend break sell\n    if row[\"Close\"] < row[\"sma_20\"]:\n        return \"SELL (TREND BREAK)\"\n\n    # 3) Strong buy breakout\n    if (\n        row[\"Close\"] > row[\"bb_upper\"]\n        and row[\"Volume\"] > (PARAM_VOL_MULT * row[\"vol_sma\"])\n        and row[\"rsi\"] > PARAM_RSI_ENTRY\n        and row[\"ko_hist\"] > 0\n        and row[\"Close\"] > row[\"vwap\"]\n    ):\n        return \"STRONG BUY (BREAKOUT)\"\n\n    # 4) Standard buy\n    if row[\"ko\"] > row[\"ko_sig\"] and row[\"rsi\"] > 50:\n        return \"BUY (TREND)\"\n\n    return \"WAIT\"\n\n\ndef decision_color(decision: str) -> str:\n    if decision.startswith(\"STRONG BUY\"):\n        return Fore.GREEN\n    if decision.startswith(\"BUY\"):\n        return Fore.CYAN\n    if decision.startswith(\"SELL (CLIMAX)\"):\n        return Fore.RED\n    if decision.startswith(\"SELL\"):\n        return Fore.MAGENTA\n    return Fore.WHITE\n\n\ndef sort_key(decision: str, ko_hist: float, sentiment: float) -> Tuple[int, float, float]:\n    \"\"\"Sorting key: higher tuple sorts earlier.\"\"\"\n    if decision.startswith(\"STRONG BUY\"):\n        tier = 5\n    elif decision.startswith(\"BUY\"):\n        tier = 4\n    elif decision.startswith(\"WAIT\"):\n        tier = 3\n    elif decision.startswith(\"SELL\"):\n        tier = 2\n    else:\n        tier = 1\n    return (tier, float(abs(ko_hist)), float(sentiment))","metadata":{},"outputs":[],"execution_count":null},{"id":"7d11093d","cell_type":"markdown","source":"## 9) Technical fetch and market analysis\n\nWe download OHLCV in **batches of 10** and sleep **2 seconds** between batches.\nThis is the main anti-rate-limit mechanism.\n\nImplementation notes:\n- `yf.download(..., group_by='ticker')` returns a multi-index column dataframe for multiple tickers.\n- For a single ticker, it returns a normal dataframe. We normalize for both cases.\n","metadata":{}},{"id":"98f95371","cell_type":"code","source":"def download_ohlcv_batch(\n    tickers: List[str],\n    session: Session,\n    period: str = YF_PERIOD,\n    interval: str = YF_INTERVAL,\n) -> Dict[str, pd.DataFrame]:\n    \"\"\"Download OHLCV for a batch of tickers and return a dict per ticker.\"\"\"\n    data = yf.download(\n        tickers,\n        period=period,\n        interval=interval,\n        group_by=\"ticker\",\n        progress=False,\n        threads=True,\n        session=session,\n    )\n\n    out: Dict[str, pd.DataFrame] = {}\n\n    if not isinstance(tickers, list):\n        tickers = list(tickers)\n\n    if len(tickers) == 1:\n        t = tickers[0]\n        if isinstance(data, pd.DataFrame) and not data.empty:\n            out[t] = data\n        return out\n\n    # Multi-ticker case\n    for t in tickers:\n        try:\n            df = data[t].copy()\n            if isinstance(df, pd.DataFrame) and not df.empty:\n                out[t] = df\n        except Exception:\n            continue\n\n    return out\n\n\ndef analyze_market(valid_candidates: List[SentimentResult]) -> List[Dict[str, Any]]:\n    print(f\"{Fore.CYAN}[*] computing technicals (batch size: {BATCH_SIZE})...\")\n\n    symbols = [x.symbol for x in valid_candidates]\n    sent_map = {x.symbol: x.score for x in valid_candidates}\n\n    report: List[Dict[str, Any]] = []\n    chunks = [symbols[i:i + BATCH_SIZE] for i in range(0, len(symbols), BATCH_SIZE)]\n    yf_session = get_yf_session()\n\n    for i, batch in enumerate(chunks, start=1):\n        try:\n            batch_data = download_ohlcv_batch(batch, session=yf_session)\n\n            for sym in batch:\n                df = batch_data.get(sym)\n                if df is None or df.empty:\n                    continue\n\n                df = df.dropna()\n                if df.empty:\n                    continue\n\n                row = compute_indicators(df)\n                if row is None:\n                    continue\n\n                decision = classify_decision(row)\n                sent_score = float(sent_map.get(sym, 50.0))\n                color = decision_color(decision)\n\n                vol_x = float(row[\"Volume\"] / (row[\"vol_sma\"] + 1e-9))\n\n                report.append({\n                    \"Symbol\": sym,\n                    \"Price\": float(row[\"Close\"]),\n                    \"Vol_X\": vol_x,\n                    \"RSI\": float(row[\"rsi\"]),\n                    \"KO_Hist\": float(row[\"ko_hist\"]),\n                    \"AO\": float(row.get(\"ao\", np.nan)),\n                    \"Sent\": sent_score,\n                    \"Decision\": f\"{color}{decision}{Style.RESET_ALL}\",\n                    \"Raw_Dec\": decision,\n                })\n\n            print(f\"{Fore.BLUE}   batch {i}/{len(chunks)} processed. sleeping {DELAY_SECONDS}s...\")\n            time.sleep(DELAY_SECONDS)\n\n        except Exception as e:\n            print(f\"{Fore.RED}[!] batch error: {e}\")\n            continue\n\n    # Sort\n    report.sort(\n        key=lambda r: sort_key(r[\"Raw_Dec\"], r[\"KO_Hist\"], r[\"Sent\"]),\n        reverse=True\n    )\n    return report","metadata":{},"outputs":[],"execution_count":null},{"id":"9f2b8a6f","cell_type":"markdown","source":"## 10) End-to-end runner (CLI-style output in notebook)\n\nThis cell runs:\n1. Discovery\n2. Sentiment filtering\n3. Technical analysis\n4. Ranked decision table\n\nIf you hit rate limits:\n- Increase DELAY_SECONDS\n- Reduce BATCH_SIZE\n- Re-run later\n","metadata":{}},{"id":"4b07e219","cell_type":"code","source":"async def run_decision_aid(max_symbols: Optional[int] = None) -> List[Dict[str, Any]]:\n    candidates = await get_candidates()\n    if not candidates:\n        print(f\"{Fore.RED}[!] no candidates received.\")\n        return []\n\n    if max_symbols is not None:\n        candidates = candidates[:max_symbols]\n\n    sentiment_filtered = await filter_by_sentiment(candidates)\n    if not sentiment_filtered:\n        print(f\"{Fore.RED}[!] no candidates passed sentiment filter.\")\n        return []\n\n    results = analyze_market(sentiment_filtered)\n\n    print(\"\\n\" + \"=\" * 90)\n    print(\"  KO-TREND DECISION AID | Strategy: Aggressive Trend Follower\")\n    print(\"=\" * 90)\n\n    headers = [\"Symbol\", \"Price\", \"Vol(x)\", \"RSI\", \"KO Hist\", \"AO\", \"Sent\", \"Decision\"]\n    rows = []\n    for r in results:\n        rows.append([\n            r[\"Symbol\"],\n            f\"{r['Price']:.2f}\",\n            f\"{r['Vol_X']:.1f}x\",\n            f\"{r['RSI']:.1f}\",\n            f\"{int(r['KO_Hist']):,}\",\n            f\"{r['AO']:.3f}\" if np.isfinite(r['AO']) else \"nan\",\n            f\"{r['Sent']:.0f}\",\n            r[\"Decision\"],\n        ])\n\n    print(tabulate(rows, headers=headers, tablefmt=\"simple\"))\n    print(\"-\" * 90)\n    print(\"[!] Vol(x): Current Vol vs 20d Avg | KO Hist: Momentum force | RSI > 95 is Climax Sell\")\n    return results\n\n\n# Run it:\n# results = await run_decision_aid(max_symbols=200)\n\n# Jupyter compatibility: use asyncio.run when no loop is running\ntry:\n    results = await run_decision_aid(max_symbols=None)  # set an int to test faster\nexcept RuntimeError:\n    results = asyncio.run(run_decision_aid(max_symbols=None))","metadata":{},"outputs":[],"execution_count":null},{"id":"5e06f35a","cell_type":"markdown","source":"## 11) Optional: inspect a single ticker with plots\n\nThis is useful for sanity checks and human validation.\n- Shows Close with Bollinger Bands and VWAP\n- Shows RSI\n- Shows KO histogram and AO\n\nRun after `results` is populated.\n","metadata":{}},{"id":"188ce285","cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef fetch_one(symbol: str) -> pd.DataFrame:\n    s = get_yf_session()\n    data = yf.download(symbol, period=YF_PERIOD, interval=YF_INTERVAL, progress=False, session=s)\n    data = data.dropna()\n    return data\n\ndef enrich_one(df: pd.DataFrame) -> pd.DataFrame:\n    df2 = df.copy()\n    latest = compute_indicators(df2)  # computes in-place copy, but returns series\n    # recompute full series for plotting by re-running compute_indicators logic without slicing\n    # simplest: call compute_indicators on copy, but we need full columns, so re-implement briefly:\n    dfp = df.copy()\n\n    dfp[\"sma_20\"] = dfp[\"Close\"].rolling(20).mean()\n    dfp[\"std_20\"] = dfp[\"Close\"].rolling(20).std(ddof=0)\n    dfp[\"bb_upper\"] = dfp[\"sma_20\"] + 2 * dfp[\"std_20\"]\n    dfp[\"bb_lower\"] = dfp[\"sma_20\"] - 2 * dfp[\"std_20\"]\n\n    delta = dfp[\"Close\"].diff()\n    gain = delta.where(delta > 0, 0.0).rolling(14).mean()\n    loss = (-delta.where(delta < 0, 0.0)).rolling(14).mean()\n    rs = gain / (loss.replace(0, np.nan))\n    dfp[\"rsi\"] = 100 - (100 / (1 + rs))\n\n    dfp[\"tp\"] = (dfp[\"High\"] + dfp[\"Low\"] + dfp[\"Close\"]) / 3.0\n    dfp[\"vwap\"] = (dfp[\"tp\"] * dfp[\"Volume\"]).cumsum() / (dfp[\"Volume\"].cumsum().replace(0, np.nan))\n\n    dfp[\"tp_diff\"] = dfp[\"tp\"].diff()\n    dfp[\"trend\"] = np.where(dfp[\"tp_diff\"] > 0, 1, -1)\n\n    dfp[\"dm\"] = dfp[\"High\"] - dfp[\"Low\"]\n    dfp[\"cm\"] = dfp[\"dm\"] + dfp[\"High\"].diff().abs() + dfp[\"Low\"].diff().abs()\n    dfp[\"cm\"] = dfp[\"cm\"].replace(0, 0.0001)\n    dfp[\"term\"] = (2 * (dfp[\"dm\"] / dfp[\"cm\"]) - 1).abs()\n    dfp[\"vf\"] = dfp[\"Volume\"] * dfp[\"trend\"] * dfp[\"term\"] * 100\n\n    dfp[\"ko\"] = dfp[\"vf\"].ewm(span=34, adjust=False).mean() - dfp[\"vf\"].ewm(span=55, adjust=False).mean()\n    dfp[\"ko_sig\"] = dfp[\"ko\"].ewm(span=13, adjust=False).mean()\n    dfp[\"ko_hist\"] = dfp[\"ko\"] - dfp[\"ko_sig\"]\n\n    mp = (dfp[\"High\"] + dfp[\"Low\"]) / 2.0\n    dfp[\"ao\"] = mp.rolling(5).mean() - mp.rolling(34).mean()\n\n    return dfp\n\ndef plot_ticker(symbol: str):\n    df = fetch_one(symbol)\n    dfp = enrich_one(df)\n\n    # Price + bands + vwap\n    plt.figure()\n    plt.plot(dfp.index, dfp[\"Close\"], label=\"Close\")\n    plt.plot(dfp.index, dfp[\"sma_20\"], label=\"BB Middle (SMA20)\")\n    plt.plot(dfp.index, dfp[\"bb_upper\"], label=\"BB Upper\")\n    plt.plot(dfp.index, dfp[\"bb_lower\"], label=\"BB Lower\")\n    plt.plot(dfp.index, dfp[\"vwap\"], label=\"VWAP (approx)\")\n    plt.title(f\"{symbol}: Price with Bollinger Bands and VWAP\")\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    # RSI\n    plt.figure()\n    plt.plot(dfp.index, dfp[\"rsi\"], label=\"RSI(14)\")\n    plt.axhline(PARAM_RSI_ENTRY, linestyle=\"--\", label=f\"Entry RSI {PARAM_RSI_ENTRY}\")\n    plt.axhline(PARAM_RSI_EXIT, linestyle=\"--\", label=f\"Exit RSI {PARAM_RSI_EXIT}\")\n    plt.title(f\"{symbol}: RSI\")\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    # KO Hist + AO\n    plt.figure()\n    plt.plot(dfp.index, dfp[\"ko_hist\"], label=\"KO Histogram\")\n    plt.plot(dfp.index, dfp[\"ao\"], label=\"Awesome Oscillator\")\n    plt.axhline(0, linestyle=\"--\")\n    plt.title(f\"{symbol}: KO Histogram and AO\")\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n# Example:\n# if results:\n#     plot_ticker(results[0]['Symbol'])","metadata":{},"outputs":[],"execution_count":null},{"id":"00281ad4","cell_type":"markdown","source":"## 12) Operational notes and extensions\n\n### Reliability and rate limits\n- If yfinance returns empty frames, it is often a throttle or symbol issue.\n- If you see repeated failures, reduce BATCH_SIZE to 5 and increase DELAY_SECONDS to 3 to 5.\n- Consider adding a disk cache (parquet) keyed by ticker and date.\n\n### Data quality\n- Trending and gainers often include low-float, high-volatility tickers.\n- This system is intentionally aggressive. Risk management is external to this notebook.\n\n### Extensions (high impact)\n1. Persist results to CSV/Parquet for daily journaling.\n2. Add sector and market cap filters (risk control).\n3. Add ATR-based position sizing and stop logic.\n4. Add multi-timeframe confirmation (weekly trend).\n5. Add a proper Wilder RSI smoothing (EMA-based) for fidelity.\n\n### Disclaimer\nThis notebook is for educational and decision-support purposes only and does not constitute financial advice.\n","metadata":{}}]}